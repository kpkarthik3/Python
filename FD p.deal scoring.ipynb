{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # imports a fast numerical programming library\n",
    "import scipy as sp #imports stats functions, amongst other things\n",
    "import matplotlib as mpl # this actually imports matplotlib\n",
    "import matplotlib.cm as cm #allows us easy access to colormaps\n",
    "import matplotlib.pyplot as plt #sets up plotting under plt\n",
    "import pandas as pd #lets us handle data as dataframes\n",
    "import math as m\n",
    "from math import cos, pi\n",
    "from itertools import cycle\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from io import StringIO\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from sklearn.ensemble import GradientBoostingClassifier #For Classification\n",
    "from sklearn.ensemble import GradientBoostingRegressor #For Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FD deal prediction model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('/Users/user/Desktop/Data Analysis/Freshsales/Raw Data/FD feature data.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data.columns = ['deal_id', \n",
    "'deal_amount',\n",
    "'source_id',\n",
    "'deal_type',\n",
    "'related_contacts_ID',\n",
    "'deal_owner_id',\n",
    "'territory_id',\n",
    "'deal_Stage',\n",
    "'product_id',\n",
    "'campaign_id',\n",
    "'created_at',\n",
    "'sales_account_id',\n",
    "'account_amount',\n",
    "'stage_updated_at',\n",
    "'contact_owner_id',\n",
    "'contact_has_authority',\n",
    "'contact_Lead_source_id',\n",
    "'contact_lead_score',\n",
    "'contact_do_not_disturb',\n",
    "'contact_open_deals_amount',\n",
    "'contact_Lead_source_id',\n",
    "'account_number_of_employees',\n",
    "'account_annual_revenue',\n",
    "'account_business_type_id',\n",
    "'account_industry_type_id',\n",
    "'account_territory_id',\n",
    "'contact_associated_deal_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data = raw_data.drop_duplicates(subset='related_contacts_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data1 = raw_data[(raw_data.deal_Stage == 'Won') | (raw_data.deal_Stage == 'Lost')]\n",
    "                   #    = df[(df['a'] > 1) & (df['a'] < 5)]\n",
    "     # . mask = df['STK_ID'].isin([4, 2, 6]) \n",
    "                     # rst = rpt[rpt['STK_ID'] in stk_list] \n",
    "            #surveys_df[(surveys_df.year >= 1980) & (surveys_df.year <= 1985)] \n",
    "            \n",
    "           # train =  raw_data[(raw_data.deal_created_at == 'Won')]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/Users/user/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/Users/user/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/user/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "#print(raw_data1['deal_Stage'])\n",
    "#len(raw_data1)\n",
    "#test = [datetime.strptime(X,'%Y-%m-%d') for X in ('2017-02-13 21:32:18\\n1')]\n",
    "#raw_data1['created_id'] = [datetime.strptime(X,'%Y-%m-%d') for X in raw_data1['created_id']]\n",
    "#pd.to_datetime(df['date'])\n",
    "#df['DateTime'] = pd.to_datetime(df['DateTime'], format='%Y%m%d', errors='ignore')\n",
    "#out= datetime.strptime('2017-02-13 21:32:18\\n1', '%Y-%m-%d  %H:%M')\n",
    "                        #[datetime.strptime(x, '%m/%d/%Y') for x in attack_dates]\n",
    "#('2017-02-13 21:32:18\\n1')\n",
    "#pd.to_datetime('2017-02-13 21:32:18\\n1', format='%Y%m%d', errors='coerce')\n",
    "#out\n",
    "raw_data1['created_at_parsed'] = raw_data1['created_at'].str.extract('(....-..-.. ..:..:..)', expand=True)\n",
    "raw_data1['created_at_parsed'] = pd.to_datetime(raw_data1['created_at_parsed'])\n",
    "raw_data1['stage_updated_at_parsed'] = raw_data1['stage_updated_at'].str.extract('(....-..-.. ..:..:..)', expand=True)\n",
    "raw_data1['stage_updated_at_parsed'] = pd.to_datetime(raw_data1['stage_updated_at_parsed'])\n",
    "\n",
    "#raw_data1['created_id'] = pd.to_datetime(raw_data1['created_id'], format='%Y%m%d', errors='ignore')\n",
    "#df['date'] = df['raw'].str.extract('(....-..-..)', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data1 = raw_data1[raw_data1.created_at_parsed < raw_data1.stage_updated_at_parsed ]\n",
    "\n",
    "train = raw_data1[raw_data1.created_at_parsed < '2017-03-01'] \n",
    "test =  raw_data1[raw_data1.created_at_parsed > '2017-03-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_features = train[[\n",
    "    'deal_id', \n",
    "'deal_amount',\n",
    "'source_id',\n",
    "'deal_type',\n",
    "'deal_owner_id',\n",
    "'territory_id',\n",
    "'product_id',\n",
    "'campaign_id',\n",
    "'account_amount',\n",
    "'contact_has_authority',\n",
    "'contact_Lead_source_id',\n",
    "'contact_lead_score',\n",
    "'contact_do_not_disturb',\n",
    "'contact_open_deals_amount',\n",
    "'contact_Lead_source_id',\n",
    "'account_number_of_employees',\n",
    "'account_annual_revenue',\n",
    "'account_business_type_id',\n",
    "'account_industry_type_id',\n",
    "'account_territory_id']]\n",
    "# test dataset\n",
    "test_features = test[[\n",
    "    'deal_id', \n",
    "'deal_amount',\n",
    "'source_id',\n",
    "'deal_type',\n",
    "'deal_owner_id',\n",
    "'territory_id',\n",
    "'product_id',\n",
    "'campaign_id',\n",
    "'account_amount',\n",
    "'contact_has_authority',\n",
    "'contact_Lead_source_id',\n",
    "'contact_lead_score',\n",
    "'contact_do_not_disturb',\n",
    "'contact_open_deals_amount',\n",
    "'contact_Lead_source_id',\n",
    "'account_number_of_employees',\n",
    "'account_annual_revenue',\n",
    "'account_business_type_id',\n",
    "'account_industry_type_id',\n",
    "'account_territory_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#y = pd.factorize(train['deal_Stage'])[0]\n",
    "#actual_value = pd.factorize(test['deal_Stage'])[0]\n",
    "y = np.where(train['deal_Stage'] == 'Won',1,0)\n",
    "actual_value = np.where(test['deal_Stage'] == 'Won',1,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#obj_train_features1 = train_features1.select_dtypes(include=['object']).copy()\n",
    "#non_obj_train_features1 = train_features1.select_dtypes( include = ['object']).copy()\n",
    "\n",
    "#lb_make = LabelEncoder()\n",
    "#obj_train_features1.columns\n",
    "#obj_df[\"make_code\"] = lb_make.fit_transform(obj_df[\"make\"])\n",
    "#obj_df[[\"make\", \"make_code\"]].head(11)\n",
    "d = defaultdict(LabelEncoder)\n",
    "# Encoding the variable\n",
    "code_test = test_features.apply(lambda test_features: d[test_features.name].fit_transform(test_features))\n",
    "code_train = train_features.apply(lambda train_features: d[train_features.name].fit_transform(train_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = tree.DecisionTreeClassifier(criterion='gini') # for classification, here you can change the algorithm as gini or entropy (information gain) by default it is gini  \n",
    "# model = tree.DecisionTreeRegressor() for regression\n",
    "# Train the model using the training sets and check score\n",
    "model.fit(code_train, y)\n",
    "#model.score(X, y)\n",
    "#Predict Output\n",
    "predicted_decision_tree= model.predict(code_test)\n",
    "predicted_prob_decision_tree = model.predict_proba(code_test) \n",
    "#len(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model= RandomForestClassifier(n_estimators=1000)\n",
    "# Train the model using the training sets and check score\n",
    "model.fit(code_train, y)\n",
    "#Predict Output\n",
    "predicted_random_forest= model.predict(code_test)\n",
    "predicted_prob_random_forest = model.predict_proba(code_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=.1, max_depth=3)\n",
    "clf.fit(code_train, y)\n",
    "predicted_Gradient_boost= clf.predict(code_test)\n",
    "predicted_prob_Gradient_boost = clf.predict_proba(code_test) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted value</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual value</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>537</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>16513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted value    0      1\n",
       "Actual value               \n",
       "0                537    120\n",
       "1                 30  16513"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create confusion matrix\n",
    "pd.crosstab(actual_value, predicted_Gradient_boost, rownames=['Actual value'], colnames=['Predicted value'])\n",
    "#predicted_prob_Gradient_boost.\n",
    "#pd.DataFrame(np.array(predicted_prob_decision_tree)).to_csv(\"/Users/user/downloads/prob.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree- Accuracy:  0.925639534884\n",
      "Decision tree- F1-Score(Weighted):  0.940380002401\n",
      "AUC score Decision tree:  0.851721554758 \n",
      " \n",
      "\n",
      "random_forest- Accuracy:  0.959186046512\n",
      "random_forest- F1-Score(Weighted):  0.96412647466\n",
      "AUC score Random forest:  0.979160484954 \n",
      " \n",
      "\n",
      "Gradient_boost- Accuracy:  0.991279069767\n",
      "Gradient_boost- F1-Score(Weighted):  0.990970276422\n",
      "AUC score Gradient Boost:  0.949967342154 \n",
      " \n",
      " \n",
      "\n",
      "Train dataset(#deals):  98172\n",
      "Test dataset(#deals):  17200\n",
      "Test- won deals 16543\n",
      "Test- lost deals 657 \n",
      " \n",
      "\n",
      "Benchmark Accuracy(predict all deals as won):  0.9618023255813953\n"
     ]
    }
   ],
   "source": [
    "false_positive_rate_tree, true_positive_rate_tree, thresholds_tree = roc_curve(actual_value, predicted_prob_decision_tree[:,1])\n",
    "false_positive_rate_ran, true_positive_rate_ran, thresholds_ran = roc_curve(actual_value, predicted_prob_random_forest[:,1])\n",
    "false_positive_rate_gboost, true_positive_rate_gboost, thresholds_gboost = roc_curve(actual_value, predicted_prob_Gradient_boost[:,1])\n",
    "print( \"Decision tree- Accuracy: \", accuracy_score(actual_value, predicted_decision_tree, normalize=True, sample_weight=None)) \n",
    "\n",
    "print( \"Decision tree- F1-Score(Weighted): \", f1_score(actual_value, predicted_decision_tree, average='weighted'))\n",
    "print( \"AUC score Decision tree: \", auc(false_positive_rate_tree, true_positive_rate_tree),\"\\n\",\"\\n\")\n",
    "\n",
    "\n",
    "print( \"random_forest- Accuracy: \", accuracy_score(actual_value, predicted_random_forest, normalize=True, sample_weight=None)) \n",
    "\n",
    "print( \"random_forest- F1-Score(Weighted): \", f1_score(actual_value, predicted_random_forest, average='weighted'))\n",
    "\n",
    "print( \"AUC score Random forest: \", auc(false_positive_rate_ran, true_positive_rate_ran),\"\\n\",\"\\n\")\n",
    "\n",
    "\n",
    "print( \"Gradient_boost- Accuracy: \", accuracy_score(actual_value, predicted_Gradient_boost, normalize=True, sample_weight=None)) \n",
    "\n",
    "print( \"Gradient_boost- F1-Score(Weighted): \", f1_score(actual_value, predicted_Gradient_boost, average='weighted'))\n",
    "\n",
    "print( \"AUC score Gradient Boost: \", auc(false_positive_rate_gboost, true_positive_rate_gboost),\"\\n\",\"\\n\",\"\\n\")\n",
    "\n",
    "print(\"Train dataset(#deals): \", len(train))\n",
    "print(\"Test dataset(#deals): \", len(test))\n",
    "print (\"Test- won deals\", len(test[test['deal_Stage'] == 'Won']))\n",
    "print ( \"Test- lost deals\", len(test[test['deal_Stage'] == 'Lost']),\"\\n\",\"\\n\")\n",
    "#print ( 1- 657 / (14770 + 1773+ 582 + 75 ))\n",
    "#len(test)\n",
    "\n",
    "print (\"Benchmark Accuracy(predict all deals as won): \", (len(test[test['deal_Stage'] == 'Won'])/(len(test[test['deal_Stage'] == 'Won']) \n",
    "                                                                        + len(test[test['deal_Stage'] == 'Lost']))))\n",
    "\n",
    "\n",
    "\n",
    "#  f1_score(actual_value, predicted, average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#y = pd.factorize(train['deal_Stage'])[0]\n",
    "#y = pd.where(train['deal_Stage'] == 'Won',0,1)\n",
    "\n",
    "#temp = pd.DataFrame(actual_value)\n",
    "#temp.columns = ['col1']\n",
    "#print (\"Train- won deals\", len(train[train['deal_Stage'] == 'Won']))\n",
    "#print ( \"Train- lost deals\", len(train[train['deal_Stage'] == 'Lost']))\n",
    "#print ( 1- 657 / (14770 + 1773+ 582 + 75 ))\n",
    "#len(test)\n",
    "\n",
    "predicted_decision_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features1['source_id'] = np.where(train_features1['source_id'] == '\\\\N','',train_features1['source_id'])\n",
    "train_features1['deal_type'] = np.where(train_features1['deal_type'] == '\\\\N','',train_features1['deal_type'])\n",
    "train_features1['deal_owner_id'] = np.where(train_features1['deal_owner_id'] == '\\\\N','',train_features1['deal_owner_id'])\n",
    "train_features1['territory_id'] = np.where(train_features1['territory_id'] == '\\\\N','',train_features1['territory_id'])\n",
    "train_features1['product_id'] = np.where(train_features1['product_id'] == '\\\\N','',train_features1['product_id'])\n",
    "train_features1['campaign_id'] = np.where(train_features1['campaign_id'] == '\\\\N','',train_features1['campaign_id'])\n",
    "#train_features1['account_amount'] = np.where(train_features1['account_amount'] == '\\\\N','',train_features1['account_amount'])\n",
    "#train_features1['contact_has_authority'] = np.where(train_features1['contact_has_authority'] == '\\\\N','',train_features1['contact_has_authority'])\n",
    "train_features1['contact_Lead_source_id'] = np.where(train_features1['contact_Lead_source_id'] == '\\\\N','',train_features1['contact_Lead_source_id'])\n",
    "#train_features1['contact_lead_score'] = np.where(train_features1['contact_lead_score'] == '\\\\N','',train_features1['contact_lead_score'])\n",
    "#train_features1['contact_do_not_disturb'] = np.where(train_features1['contact_do_not_disturb'] == '\\\\N','',train_features1['contact_do_not_disturb'])\n",
    "#train_features1['contact_open_deals_amount'] = np.where(train_features1['contact_open_deals_amount'] == '\\\\N','',train_features1['contact_open_deals_amount'])\n",
    "train_features1['contact_Lead_source_id'] = np.where(train_features1['contact_Lead_source_id'] == '\\\\N','',train_features1['contact_Lead_source_id'])\n",
    "train_features1['account_number_of_employees'] = np.where(train_features1['account_number_of_employees'] == '\\\\N','',train_features1['account_number_of_employees'])\n",
    "train_features1['account_annual_revenue'] = np.where(train_features1['account_annual_revenue'] == '\\\\N','',train_features1['account_annual_revenue'])\n",
    "train_features1['account_business_type_id'] = np.where(train_features1['account_business_type_id'] == '\\\\N','',train_features1['account_business_type_id'])\n",
    "train_features1['account_industry_type_id'] = np.where(train_features1['account_industry_type_id'] == '\\\\N','',train_features1['account_industry_type_id'])\n",
    "train_features1['account_territory_id'] = np.where(train_features1['account_territory_id'] == '\\\\N','',train_features1['account_territory_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test[['deal_id', \n",
    "'deal_amount',\n",
    "'source_id',\n",
    "'deal_type',\n",
    "'deal_owner_id',\n",
    "'territory_id',\n",
    "'product_id',\n",
    "'campaign_id',\n",
    "'account_amount',\n",
    "'contact_has_authority',\n",
    "'contact_Lead_source_id',\n",
    "'contact_lead_score',\n",
    "'contact_do_not_disturb',\n",
    "'contact_open_deals_amount',\n",
    "'contact_Lead_source_id',\n",
    "'account_number_of_employees',\n",
    "'account_annual_revenue',\n",
    "'account_business_type_id',\n",
    "'account_industry_type_id',\n",
    "'account_territory_id']]\n",
    "\n",
    "\n",
    "## object fields \n",
    "'deal_id', 'source_id', 'deal_type', 'deal_owner_id', 'territory_id',\n",
    "       'product_id', 'campaign_id', 'contact_Lead_source_id',\n",
    "       'contact_Lead_source_id', 'contact_Lead_source_id',\n",
    "       'contact_Lead_source_id', 'account_number_of_employees',\n",
    "       'account_annual_revenue', 'account_business_type_id',\n",
    "       'account_industry_type_id', 'account_territory_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "lb_make = LabelEncoder()\n",
    "obj_train_features1['source_id_code']= lb_make.fit_transform(obj_train_features1['source_id'])\n",
    "#obj_train_features1['source_id','source_id_code']\n",
    "#obj_df[[\"make\", \"make_code\"]].head(11)\n",
    "obj_train_features1.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "le=LabelEncoder()\n",
    "# Iterating over all the common columns in train and test\n",
    "for col in test_features.columns.values:\n",
    "       # Encoding only categorical variables\n",
    "    print (test_features[col].dtypes)\n",
    "    if test_features[col].dtypes == 'object':\n",
    "     print(\"inside if\")   \n",
    "       # Using whole data to form an exhaustive list of levels\n",
    "     data=train_features[col].append(test_features[col])\n",
    "     le.fit(data.values)\n",
    "     train_features[col]=le.transform(train_features[col])\n",
    "     test_features[col]=le.transform(test_features[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " test_features.columns.to_series().groupby(test_features.dtypes).groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#raw_data.head()\n",
    "#len(raw_data1)\n",
    "#raw_data1.head(10)\n",
    "\n",
    "#raw_data1['created_id'].head(100)\n",
    "#raw_data1['created_id'].describe()\n",
    "#raw_data1['stage_updated_at_parsed'].hea\n",
    "#test_features.columns\n",
    "#train_features1['source_id'].unique()\n",
    "#train_features1 = train_features\n",
    "#Fd_Test['actual_value'] = np.where(Fd_Test['leadstage'] == 'Won', 1,0 )\n",
    "#train_features1['source_id'] = np.where(train_features1['source_id'] == '\\\\N','',train_features1['source_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(raw_data.groupby('deal_id')['related_contacts_ID'].count())\n",
    "temp['related_contacts_ID'].quantile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.percentile(temp['related_contacts_ID'],99, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data1['deal_Stage'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data1['created_id'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
